import cv2
import numpy as np
import util

# RootSift + Load Feature + ROI detection + BF matcher + single captured image
# Dependency: rootsift.py + feature.py

def detection(p, camera, labels, products, product):
    try:
        index = products.index(product)
        label = labels[index]
        kp_tmp, des_tmp = util.unpickle_keypoints(label)
        print("[INFO] Product included")
    except:
        print("[INFO] Product is not included!")
    # Grab a single camera image
    captured_img = util.getImgFromCamera(camera)
    # Resize captured image
    cap_rows, cap_cols, cap_channels = captured_img.shape
    cap_scaled = cv2.resize(captured_img, (int(cap_cols * p.resize_img), int(cap_rows * p.resize_img)),
                            interpolation=cv2.INTER_AREA)
    # find the keypoints and descriptors with RootSIFT
    rs = util.RootSIFT()
    kp_cap_scaled, des_cap_scaled = rs.compute(cap_scaled)
    # BF matching
    first_matching_points = util.bruteForce(des_tmp, des_cap_scaled, p.first_matching_level)
    print("[INFO] Good matching pairs of first match: " + str(len(first_matching_points)))

    if len(first_matching_points) >= p.first_match_count:
        src_pts = np.float32([kp_tmp[m.queryIdx].pt for m in first_matching_points]).reshape(-1, 1, 2)
        dst_pts = np.float32([kp_cap_scaled[m.trainIdx].pt for m in first_matching_points]).reshape(-1, 1, 2)
        try:
            M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)
        except:
            print("[WARNING] Fail to perform homography.")
        #matchesMask = mask.ravel().tolist()
        # h, w = template_img.shape
        h = p.template_height
        w = p.template_width
        # h, w, d= template_img.shape
        pts = np.float32([[0, 0], [0, h - 1], [w - 1, h - 1], [w - 1, 0]]).reshape(-1, 1, 2)
        dst = cv2.perspectiveTransform(pts, M)
        max_index = np.max(np.int32(dst / p.resize_img), axis=0)
        min_index = np.min(np.int32(dst / p.resize_img), axis=0)
        #  top-left point:       (x,y) -> (min_index[0, 0], min_index[0, 1])
        #  bottom-right point:   (x,y) -> (max_index[0, 0], max_index[0, 1])
        width = abs(min_index[0, 1] - max_index[0, 1])
        height = abs(min_index[0, 0] - max_index[0, 0])
        if min_index[0, 0] >= 0 and max_index[0, 0] < cap_cols and min_index[0, 1] >= 0 and max_index[
            0, 1] < cap_rows and width >= p.min_size and height >= p.min_size:
            # height from min_index[0, 1] to max_index[0, 1];
            # width  from min_index[0, 0] to max_index[0, 0];
            cap_crop = captured_img[min_index[0, 1]:max_index[0, 1], min_index[0, 0]:max_index[0, 0]]

            crop_rows, crop_cols, crop_channels = cap_crop.shape
            cap_crop = cv2.resize(cap_crop, (int(crop_cols * p.resize_crop), int(crop_rows * p.resize_crop)),
                                  interpolation=cv2.INTER_AREA)
            cv2.imshow("cropped image", cap_crop)
            print("[INFO] resolution of croped image: " + str(cap_crop.shape[0]) + " * " + str(cap_crop.shape[1]))
            kp_cap_crop, des_cap_crop = rs.compute(cap_crop)

            try:
                second_matching_points = util.bruteForce(des_tmp, des_cap_crop, p.second_matching_level)
            except:
                #exit()
                print("[INFO] Not matching: second matching failed.")
                status = "Not matching: second matching failed"
                statusCode = "102"
                captured_img = cv2.resize(captured_img, (int(cap_cols * 0.2), int(cap_rows * 0.2)),
                                        interpolation=cv2.INTER_AREA)
                cv2.imwrite('result.jpg', captured_img)
                return status

            # img2 = cv.polylines(cap_scaled,[np.int32(dst)],True,255,3, cv.LINE_AA)
            print("[INFO] Good matching pairs of second match: " + str(len(second_matching_points)))
            score = util.getScore(second_matching_points, width, height)
            print("[INFO] score = " + str(score))
            if score >= p.score_thresh and len(second_matching_points) >= p.second_match_count:
                print("[INFO] Matching!!!")
                status = "Matching"
                statusCode = "201"
                captured_img = cv2.polylines(captured_img, [np.int32(dst / p.resize_img)], True, (0,0,255), 13, cv2.LINE_AA)
                #cv2.imshow("results", captured_img)
                captured_img = cv2.resize(captured_img, (int(cap_cols * 0.2), int(cap_rows * 0.2)),
                                        interpolation=cv2.INTER_AREA)
                cv2.imwrite('result.jpg', captured_img)
            else:
                print("[INFO] Not matching: <threshold")
                status = "Not matching: score <threshold"
                statusCode = "103"
                #cv2.imshow("results", captured_img)
                captured_img = cv2.resize(captured_img, (int(cap_cols * 0.2), int(cap_rows * 0.2)),
                                        interpolation=cv2.INTER_AREA)
                cv2.imwrite('result.jpg', captured_img)
        elif (width < p.min_size and width > 0) or (height < p.min_size and height > 0):
            print("[INFO] Not matching: too small size !")
            status = "Not matching: ROI too small"
            statusCode = "104"
            cap_crop = captured_img[min_index[0, 1]:max_index[0, 1], min_index[0, 0]:max_index[0, 0]]
            # print("resolution of croped image= " + str(max_index[0, 0] - min_index[0, 0]) + "*" + str(max_index[0, 1] - min_index[0, 1]) + "(h * w)")
            # cv2.imshow("cropped image", cap_crop)
            #cv2.imshow("results", captured_img)
            captured_img = cv2.resize(captured_img, (int(cap_cols * 0.2), int(cap_rows * 0.2)),
                                      interpolation=cv2.INTER_AREA)
            cv2.imwrite('result.jpg', captured_img)
        else:
            print("[INFO] Not matching: ROI out of range !")
            status = "Not matching: ROI out of range"
            statusCode = "105"
            #cv2.imshow("results", captured_img)
            captured_img = cv2.resize(captured_img, (int(cap_cols * 0.2), int(cap_rows * 0.2)),
                                      interpolation=cv2.INTER_AREA)
            cv2.imwrite('result.jpg', captured_img)
    else:
        print("[INFO] Not matching: first matching pairs < required !")
        status = "Not matching: first matching pairs < required"
        statusCode = "101"
        #cv2.imshow("results", captured_img)
        captured_img = cv2.resize(captured_img, (int(cap_cols * 0.2), int(cap_rows * 0.2)),
                                  interpolation=cv2.INTER_AREA)
        cv2.imwrite('result.jpg', captured_img)
    cv2.waitKey(1)
    return status, statusCode

def detectionCam(p, camera, labels, products, product):
    try:
        index = products.index(product)
        label = labels[index]
        kp_tmp, des_tmp = util.unpickle_keypoints(label)
        print("[INFO] Product included")
    except:
        print("[INFO] Product is not included!")
    # Grab a single camera image
    captured_img = util.getImgFromCamera(camera)
    # Resize captured image
    cap_rows, cap_cols, cap_channels = captured_img.shape
    cap_scaled = cv2.resize(captured_img, (int(cap_cols * p.resize_img), int(cap_rows * p.resize_img)),
                            interpolation=cv2.INTER_AREA)
    # find the keypoints and descriptors with RootSIFT
    rs = util.RootSIFT()
    kp_cap_scaled, des_cap_scaled = rs.compute(cap_scaled)
    # BF matching
    first_matching_points = util.bruteForce(des_tmp, des_cap_scaled, p.first_matching_level)
    print("[INFO] Good matching pairs of first match: " + str(len(first_matching_points)))

    if len(first_matching_points) >= p.first_match_count:
        src_pts = np.float32([kp_tmp[m.queryIdx].pt for m in first_matching_points]).reshape(-1, 1, 2)
        dst_pts = np.float32([kp_cap_scaled[m.trainIdx].pt for m in first_matching_points]).reshape(-1, 1, 2)
        try:
            M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)
        except:
            print("[WARNING] Fail to perform homography.")
        #matchesMask = mask.ravel().tolist()
        # h, w = template_img.shape
        h = p.template_height
        w = p.template_width
        # h, w, d= template_img.shape
        pts = np.float32([[0, 0], [0, h - 1], [w - 1, h - 1], [w - 1, 0]]).reshape(-1, 1, 2)
        dst = cv2.perspectiveTransform(pts, M)
        max_index = np.max(np.int32(dst / p.resize_img), axis=0)
        min_index = np.min(np.int32(dst / p.resize_img), axis=0)
        #  top-left point:       (x,y) -> (min_index[0, 0], min_index[0, 1])
        #  bottom-right point:   (x,y) -> (max_index[0, 0], max_index[0, 1])
        width = abs(min_index[0, 1] - max_index[0, 1])
        height = abs(min_index[0, 0] - max_index[0, 0])
        if min_index[0, 0] >= 0 and max_index[0, 0] < cap_cols and min_index[0, 1] >= 0 and max_index[
            0, 1] < cap_rows and width >= p.min_size and height >= p.min_size:
            # height from min_index[0, 1] to max_index[0, 1];
            # width  from min_index[0, 0] to max_index[0, 0];
            cap_crop = captured_img[min_index[0, 1]:max_index[0, 1], min_index[0, 0]:max_index[0, 0]]

            crop_rows, crop_cols, crop_channels = cap_crop.shape
            cap_crop = cv2.resize(cap_crop, (int(crop_cols * p.resize_crop), int(crop_rows * p.resize_crop)),
                                  interpolation=cv2.INTER_AREA)
            cv2.imshow("cropped image", cap_crop)
            print("[INFO] resolution of croped image: " + str(cap_crop.shape[0]) + " * " + str(cap_crop.shape[1]))
            kp_cap_crop, des_cap_crop = rs.compute(cap_crop)

            try:
                second_matching_points = util.bruteForce(des_tmp, des_cap_crop, p.second_matching_level)
            except:
                #exit()
                print("[INFO] Not matching: second matching failed.")
                status = "Not matching: second matching failed"
                statusCode = "102"
                captured_img = cv2.resize(captured_img, (int(cap_cols * 0.2), int(cap_rows * 0.2)),
                                        interpolation=cv2.INTER_AREA)
                cv2.imwrite('result.jpg', captured_img)
                return status

            # img2 = cv.polylines(cap_scaled,[np.int32(dst)],True,255,3, cv.LINE_AA)
            print("[INFO] Good matching pairs of second match: " + str(len(second_matching_points)))
            score = util.getScore(second_matching_points, width, height)
            print("[INFO] score = " + str(score))
            if score >= p.score_thresh and len(second_matching_points) >= p.second_match_count:
                print("[INFO] Matching!!!")
                status = "Matching"
                statusCode = "201"
                captured_img = cv2.polylines(captured_img, [np.int32(dst / p.resize_img)], True, (0,255,0), 13, cv2.LINE_AA)
                captured_img = cv2.resize(captured_img, (int(cap_cols * 0.2), int(cap_rows * 0.2)),
                                        interpolation=cv2.INTER_AREA)
                cv2.imshow("results", captured_img)
                cv2.imwrite('result.jpg', captured_img)
            else:
                print("[INFO] Not matching: <threshold")
                status = "Not matching: score <threshold"
                statusCode = "103"
                captured_img = cv2.resize(captured_img, (int(cap_cols * 0.2), int(cap_rows * 0.2)),
                                        interpolation=cv2.INTER_AREA)
                cv2.imshow("results", captured_img)
                cv2.imwrite('result.jpg', captured_img)
        elif (width < p.min_size and width > 0) or (height < p.min_size and height > 0):
            print("[INFO] Not matching: too small size !")
            status = "Not matching: ROI too small"
            statusCode = "104"
            cap_crop = captured_img[min_index[0, 1]:max_index[0, 1], min_index[0, 0]:max_index[0, 0]]
            # print("resolution of croped image= " + str(max_index[0, 0] - min_index[0, 0]) + "*" + str(max_index[0, 1] - min_index[0, 1]) + "(h * w)")
            # cv2.imshow("cropped image", cap_crop)
            captured_img = cv2.resize(captured_img, (int(cap_cols * 0.2), int(cap_rows * 0.2)),
                                      interpolation=cv2.INTER_AREA)
            cv2.imshow("results", captured_img)
            cv2.imwrite('result.jpg', captured_img)
        else:
            print("[INFO] Not matching: ROI out of range !")
            status = "Not matching: ROI out of range"
            statusCode = "105"
            captured_img = cv2.resize(captured_img, (int(cap_cols * 0.2), int(cap_rows * 0.2)),
                                      interpolation=cv2.INTER_AREA)
            cv2.imshow("results", captured_img)
            cv2.imwrite('result.jpg', captured_img)
    else:
        print("[INFO] Not matching: first matching pairs < required !")
        status = "Not matching: first matching pairs < required"
        statusCode = "101"
        captured_img = cv2.resize(captured_img, (int(cap_cols * 0.2), int(cap_rows * 0.2)),
                                  interpolation=cv2.INTER_AREA)
        cv2.imshow("results", captured_img)
        cv2.imwrite('result.jpg', captured_img)
    cv2.waitKey(2000)
    return status, statusCode

def detectionImg(p, captured_img, labels, products, product):
    try:
        index = products.index(product)
        label = labels[index]
        kp_tmp, des_tmp = util.unpickle_keypoints(label)
        print("[INFO] Product included")
    except:
        print("[INFO] Product is not included!")
    # Resize captured image
    cap_rows, cap_cols, cap_channels = captured_img.shape
    cap_scaled = cv2.resize(captured_img, (int(cap_cols * p.resize_img), int(cap_rows * p.resize_img)),
                            interpolation=cv2.INTER_AREA)
    # find the keypoints and descriptors with RootSIFT
    rs = util.RootSIFT()
    kp_cap_scaled, des_cap_scaled = rs.compute(cap_scaled)
    # BF matching
    first_matching_points = util.bruteForce(des_tmp, des_cap_scaled, p.first_matching_level)
    print("[INFO] Good matching pairs of first match: " + str(len(first_matching_points)))

    if len(first_matching_points) >= p.first_match_count:
        src_pts = np.float32([kp_tmp[m.queryIdx].pt for m in first_matching_points]).reshape(-1, 1, 2)
        dst_pts = np.float32([kp_cap_scaled[m.trainIdx].pt for m in first_matching_points]).reshape(-1, 1, 2)
        try:
            M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)
        except:
            print("[WARNING] Fail to perform homography.")
        #matchesMask = mask.ravel().tolist()
        # h, w = template_img.shape
        h = p.template_height
        w = p.template_width
        # h, w, d= template_img.shape
        pts = np.float32([[0, 0], [0, h - 1], [w - 1, h - 1], [w - 1, 0]]).reshape(-1, 1, 2)
        dst = cv2.perspectiveTransform(pts, M)
        max_index = np.max(np.int32(dst / p.resize_img), axis=0)
        min_index = np.min(np.int32(dst / p.resize_img), axis=0)
        #  top-left point:       (x,y) -> (min_index[0, 0], min_index[0, 1])
        #  bottom-right point:   (x,y) -> (max_index[0, 0], max_index[0, 1])
        width = abs(min_index[0, 1] - max_index[0, 1])
        height = abs(min_index[0, 0] - max_index[0, 0])
        if min_index[0, 0] >= 0 and max_index[0, 0] < cap_cols and min_index[0, 1] >= 0 and max_index[
            0, 1] < cap_rows and width >= p.min_size and height >= p.min_size:
            # height from min_index[0, 1] to max_index[0, 1];
            # width  from min_index[0, 0] to max_index[0, 0];
            cap_crop = captured_img[min_index[0, 1]:max_index[0, 1], min_index[0, 0]:max_index[0, 0]]

            crop_rows, crop_cols, crop_channels = cap_crop.shape
            cap_crop = cv2.resize(cap_crop, (int(crop_cols * p.resize_crop), int(crop_rows * p.resize_crop)),
                                  interpolation=cv2.INTER_AREA)
            cv2.imshow("cropped image", cap_crop)
            print("[INFO] resolution of croped image: " + str(cap_crop.shape[0]) + " * " + str(cap_crop.shape[1]))
            kp_cap_crop, des_cap_crop = rs.compute(cap_crop)

            try:
                second_matching_points = util.bruteForce(des_tmp, des_cap_crop, p.second_matching_level)
            except:
                #exit()
                status = "Not matching: second matching failed"
                print("[INFO] " + status)
                statusCode = "102"
                captured_img = cv2.resize(captured_img, (int(cap_cols * 0.2), int(cap_rows * 0.2)),
                                        interpolation=cv2.INTER_AREA)
                cv2.imwrite('result.jpg', captured_img)
                return status

            # img2 = cv.polylines(cap_scaled,[np.int32(dst)],True,255,3, cv.LINE_AA)
            print("[INFO] Good matching pairs of second match: " + str(len(second_matching_points)))
            score = util.getScore(second_matching_points, width, height)
            print("[INFO] score = " + str(score))
            if score >= p.score_thresh and len(second_matching_points) >= p.second_match_count:
                status = "Matching"
                print("[INFO] " + status)
                statusCode = "201"
                captured_img = cv2.polylines(captured_img, [np.int32(dst / p.resize_img)], True, (0,255,0), 13, cv2.LINE_AA)
                captured_img = cv2.resize(captured_img, (int(cap_cols * 0.2), int(cap_rows * 0.2)),
                                        interpolation=cv2.INTER_AREA)
                cv2.imshow("results", captured_img)
                cv2.imwrite('result.jpg', captured_img)
            else:
                status = "Not matching: score <threshold"
                print("[INFO] " + status)
                statusCode = "103"
                captured_img = cv2.resize(captured_img, (int(cap_cols * 0.2), int(cap_rows * 0.2)),
                                        interpolation=cv2.INTER_AREA)
                cv2.imshow("results", captured_img)
                cv2.imwrite('result.jpg', captured_img)
        elif (width < p.min_size and width > 0) or (height < p.min_size and height > 0):
            status = "Not matching: ROI too small"
            print("[INFO] " + status)
            statusCode = "104"
            cap_crop = captured_img[min_index[0, 1]:max_index[0, 1], min_index[0, 0]:max_index[0, 0]]
            # print("resolution of croped image= " + str(max_index[0, 0] - min_index[0, 0]) + "*" + str(max_index[0, 1] - min_index[0, 1]) + "(h * w)")
            # cv2.imshow("cropped image", cap_crop)
            captured_img = cv2.resize(captured_img, (int(cap_cols * 0.2), int(cap_rows * 0.2)),
                                      interpolation=cv2.INTER_AREA)
            cv2.imshow("results", captured_img)
            cv2.imwrite('result.jpg', captured_img)
        else:
            status = "Not matching: ROI out of range"
            print("[INFO] " + status)
            statusCode = "105"
            captured_img = cv2.resize(captured_img, (int(cap_cols * 0.2), int(cap_rows * 0.2)),
                                      interpolation=cv2.INTER_AREA)
            cv2.imshow("results", captured_img)
            cv2.imwrite('result.jpg', captured_img)
    else:
        status = "Not matching: first matching pairs < required"
        print("[INFO] " + status)
        statusCode = "101"
        #cv2.imshow("results", captured_img)
        captured_img = cv2.resize(captured_img, (int(cap_cols * 0.2), int(cap_rows * 0.2)),
                                  interpolation=cv2.INTER_AREA)
        cv2.imshow("results", captured_img)
        cv2.imwrite('result.jpg', captured_img)
    cv2.waitKey(2000)
    return status, statusCode

def detectionImgEx(p, captured_img, labels, products, positions, product):
    try:
        index = products.index(product)
        label = labels[index]
        position = positions[index]
        kp_tmp, des_tmp = util.unpickle_keypoints(label)
        print("[INFO] Product included")
    except:
        print("[INFO] Product is not included!")
    # Resize captured image
    cap_rows, cap_cols, cap_channels = captured_img.shape
    cap_scaled = cv2.resize(captured_img, (int(cap_cols * p.resize_img), int(cap_rows * p.resize_img)),
                            interpolation=cv2.INTER_AREA)
    # find the keypoints and descriptors with RootSIFT
    rs = util.RootSIFT()
    kp_cap_scaled, des_cap_scaled = rs.compute(cap_scaled)
    # BF matching
    first_matching_points = util.bruteForce(des_tmp, des_cap_scaled, p.first_matching_level)
    print("[INFO] Good matching pairs of first match: " + str(len(first_matching_points)))

    if len(first_matching_points) >= p.first_match_count:
        src_pts = np.float32([kp_tmp[m.queryIdx].pt for m in first_matching_points]).reshape(-1, 1, 2)
        dst_pts = np.float32([kp_cap_scaled[m.trainIdx].pt for m in first_matching_points]).reshape(-1, 1, 2)
        try:
            M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)
        except:
            print("[WARNING] Fail to perform homography.")
        #matchesMask = mask.ravel().tolist()
        # h, w = template_img.shape
        #h = p.template_height
        #w = p.template_width
        h = int((position[1][1] - position[0][1] + 1) * p.resize_crop)
        w = int((position[1][0] - position[0][0] + 1) * p.resize_crop)
        # h, w, d= template_img.shape
        pts = np.float32([[0, 0], [0, h - 1], [w - 1, h - 1], [w - 1, 0]]).reshape(-1, 1, 2)
        #pts = np.float32([position[0], [position[0][0], position[1][1]], position[1], [position[1][0], position[0][1]]]).reshape(-1, 1, 2)
        #pts = np.float32([[68, 16], [68, 788], [540, 788], [540, 16]]).reshape(-1, 1, 2)
        dst = cv2.perspectiveTransform(pts, M)
        max_index = np.max(np.int32(dst / p.resize_img), axis=0)
        min_index = np.min(np.int32(dst / p.resize_img), axis=0)
        #  top-left point:       (x,y) -> (min_index[0, 0], min_index[0, 1])
        #  bottom-right point:   (x,y) -> (max_index[0, 0], max_index[0, 1])
        width = abs(min_index[0, 1] - max_index[0, 1])
        height = abs(min_index[0, 0] - max_index[0, 0])
        if min_index[0, 0] >= 0 and max_index[0, 0] < cap_cols and min_index[0, 1] >= 0 and max_index[
            0, 1] < cap_rows and width >= p.min_size and height >= p.min_size:
            # height from min_index[0, 1] to max_index[0, 1];
            # width  from min_index[0, 0] to max_index[0, 0];
            cap_crop = captured_img[min_index[0, 1]:max_index[0, 1], min_index[0, 0]:max_index[0, 0]]

            pts3 = np.float32([[0,12],[23,119],[87,119],[74,0]])
            pts4 = np.float32([[0, 0], [0, 500], [300, 500], [300, 0]])
            #pts3 = np.float32([[56, 65], [368, 52], [28, 387], [389, 390]])
            #pts4 = np.float32([[0, 0], [300, 0], [0, 300], [300, 300]])
            M_perspective = cv2.getPerspectiveTransform(pts3, pts4)
            img_perspective = cv2.warpPerspective(cap_crop, M_perspective, (300, 500))
            cv2.imshow("TTT", img_perspective)

            # pts3 = np.float32([[56, 65], [368, 52], [28, 387], [389, 390]])
            # pts4 = np.float32([[0, 0], [300, 0], [0, 300], [300, 300]])
            # M_perspective = cv2.getPerspectiveTransform(pts3, pts4)
            # img_perspective = cv2.warpPerspective(cap_crop, M_perspective, (300, 300))

            #PerspectiveMatrix = cv2.getPerspectiveTransform(dst, np.array(CanvasPointsA))

            #PerspectiveImg = cv2.warpPerspective(cap_crop, PerspectiveMatrix, (300, 300))




            crop_rows, crop_cols, crop_channels = cap_crop.shape
            cap_crop = cv2.resize(cap_crop, (int(crop_cols * p.resize_crop), int(crop_rows * p.resize_crop)),
                                  interpolation=cv2.INTER_AREA)
            cv2.imshow("cropped image", cap_crop)
            # cv2.imshow("TTT", img_perspective)
            print("[INFO] resolution of croped image: " + str(cap_crop.shape[0]) + " * " + str(cap_crop.shape[1]))
            kp_cap_crop, des_cap_crop = rs.compute(cap_crop)

            try:
                second_matching_points = util.bruteForce(des_tmp, des_cap_crop, p.second_matching_level)
            except:
                #exit()
                status = "Not matching: second matching failed"
                print("[INFO] " + status)
                statusCode = "102"
                captured_img = cv2.resize(captured_img, (int(cap_cols * 0.2), int(cap_rows * 0.2)),
                                        interpolation=cv2.INTER_AREA)
                cv2.imwrite('result.jpg', captured_img)
                return status

            # img2 = cv.polylines(cap_scaled,[np.int32(dst)],True,255,3, cv.LINE_AA)
            print("[INFO] Good matching pairs of second match: " + str(len(second_matching_points)))
            score = util.getScore(second_matching_points, width, height)
            print("[INFO] score = " + str(score))
            if score >= p.score_thresh and len(second_matching_points) >= p.second_match_count:
                status = "Matching"
                print("[INFO] " + status)
                statusCode = "201"
                captured_img = cv2.polylines(captured_img, [np.int32(dst / p.resize_img)], True, (0,255,0), 13, cv2.LINE_AA)
                captured_img = cv2.resize(captured_img, (int(cap_cols * 0.2), int(cap_rows * 0.2)),
                                        interpolation=cv2.INTER_AREA)
                cv2.imshow("results", captured_img)
                cv2.imwrite('result.jpg', captured_img)
            else:
                status = "Not matching: score <threshold"
                print("[INFO] " + status)
                statusCode = "103"
                captured_img = cv2.resize(captured_img, (int(cap_cols * 0.2), int(cap_rows * 0.2)),
                                        interpolation=cv2.INTER_AREA)
                cv2.imshow("results", captured_img)
                cv2.imwrite('result.jpg', captured_img)
        elif (width < p.min_size and width > 0) or (height < p.min_size and height > 0):
            status = "Not matching: ROI too small"
            print("[INFO] " + status)
            statusCode = "104"
            cap_crop = captured_img[min_index[0, 1]:max_index[0, 1], min_index[0, 0]:max_index[0, 0]]
            # print("resolution of croped image= " + str(max_index[0, 0] - min_index[0, 0]) + "*" + str(max_index[0, 1] - min_index[0, 1]) + "(h * w)")
            # cv2.imshow("cropped image", cap_crop)
            captured_img = cv2.resize(captured_img, (int(cap_cols * 0.2), int(cap_rows * 0.2)),
                                      interpolation=cv2.INTER_AREA)
            cv2.imshow("results", captured_img)
            cv2.imwrite('result.jpg', captured_img)
        else:
            status = "Not matching: ROI out of range"
            print("[INFO] " + status)
            statusCode = "105"
            captured_img = cv2.resize(captured_img, (int(cap_cols * 0.2), int(cap_rows * 0.2)),
                                      interpolation=cv2.INTER_AREA)
            cv2.imshow("results", captured_img)
            cv2.imwrite('result.jpg', captured_img)
    else:
        status = "Not matching: first matching pairs < required"
        print("[INFO] " + status)
        statusCode = "101"
        #cv2.imshow("results", captured_img)
        captured_img = cv2.resize(captured_img, (int(cap_cols * 0.2), int(cap_rows * 0.2)),
                                  interpolation=cv2.INTER_AREA)
        cv2.imshow("results", captured_img)
        cv2.imwrite('result.jpg', captured_img)
    cv2.waitKey(2000)
    return status, statusCode


if __name__ == '__main__':
    # initilize parameters
    p = util.Parameter()
    #camera, labels, products = util.initCamEnv("labels.pkl")
    #labels, products = util.initImgEnv("labels.pkl")
    labels, products, positions = util.initImgEnvEx("labels.pkl")
    product = "NV230C"
    #product = "147GHN"
    #product = "182CST"
    print("[INFO] Product: " + product)

    img = cv2.imread('test2.bmp', 1)
    #str_status, str_statusCode = detectionImg(p, img, labels, products, product)
    #str_status, str_statusCode = detectionCam(p, camera, labels, products, product)
    str_status, str_statusCode = detectionImgEx(p, img, labels, products, positions, product)
    #print(p.score_thresh)

    print("[INFO] Detection ends")


